{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Layer\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "K = tf.keras.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1,2,3],[2,3,4]])\n",
    "y = tf.reduce_sum(x)\n",
    "with tf.Session():\n",
    "  # We can also use 'c.eval()' here.\n",
    "  print(y.eval())\n",
    "    \n",
    "    \n",
    "    \n",
    "w= Layer.__dict__.keys()\n",
    "\n",
    "from deepctr.inputs import DEFAULT_GROUP_NAME\n",
    "from deepctr.inputs import  build_input_features\n",
    "from deepctr.inputs import input_from_feature_columns, get_linear_logit, build_input_features, combined_dnn_input, DEFAULT_GROUP_NAME\n",
    "fm_group=[DEFAULT_GROUP_NAME]\n",
    "dnn_hidden_units=(128, 128)\n",
    "l2_reg_linear=0.00001\n",
    "l2_reg_embedding=0.00001\n",
    "l2_reg_dnn=0\n",
    "init_std=0.0001\n",
    "seed=1024\n",
    "dnn_dropout=0,\n",
    "dnn_activation='relu'\n",
    "dnn_use_bn=False\n",
    "task='binary'\n",
    "\n",
    "\n",
    "features = build_input_features(\n",
    "    linear_feature_columns + dnn_feature_columns)\n",
    "inputs_list = list(features.values())\n",
    "\n",
    "from deepctr.inputs import  input_from_feature_columns\n",
    "group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,\n",
    "                                                                    init_std, seed, support_group=True)\n",
    "# group_embedding_dict default_group sparse_emd  (?,1,1)\n",
    "# dense_value_list dense (?,1)\n",
    "\n",
    "\n",
    "from deepctr.inputs import input_from_feature_columns, get_linear_logit, build_input_features, combined_dnn_input, DEFAULT_GROUP_NAME\n",
    "linear_logit = get_linear_logit(features, linear_feature_columns, init_std=init_std, seed=seed, prefix='linear',\n",
    "                                l2_reg=l2_reg_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'no_mask_9_1/no_mask_9/Identity:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('C1', <tf.Tensor 'C1_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C2', <tf.Tensor 'C2_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C3', <tf.Tensor 'C3_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C4', <tf.Tensor 'C4_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C5', <tf.Tensor 'C5_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C6', <tf.Tensor 'C6_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C7', <tf.Tensor 'C7_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C8', <tf.Tensor 'C8_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C9', <tf.Tensor 'C9_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C10', <tf.Tensor 'C10_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C11', <tf.Tensor 'C11_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C12', <tf.Tensor 'C12_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C13', <tf.Tensor 'C13_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C14', <tf.Tensor 'C14_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C15', <tf.Tensor 'C15_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C16', <tf.Tensor 'C16_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C17', <tf.Tensor 'C17_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C18', <tf.Tensor 'C18_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C19', <tf.Tensor 'C19_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C20', <tf.Tensor 'C20_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C21', <tf.Tensor 'C21_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C22', <tf.Tensor 'C22_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C23', <tf.Tensor 'C23_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C24', <tf.Tensor 'C24_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C25', <tf.Tensor 'C25_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('C26', <tf.Tensor 'C26_5:0' shape=(?, 1) dtype=int32>),\n",
       "             ('I1', <tf.Tensor 'I1_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I2', <tf.Tensor 'I2_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I3', <tf.Tensor 'I3_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I4', <tf.Tensor 'I4_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I5', <tf.Tensor 'I5_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I6', <tf.Tensor 'I6_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I7', <tf.Tensor 'I7_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I8', <tf.Tensor 'I8_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I9', <tf.Tensor 'I9_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I10', <tf.Tensor 'I10_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I11', <tf.Tensor 'I11_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I12', <tf.Tensor 'I12_5:0' shape=(?, 1) dtype=float32>),\n",
       "             ('I13', <tf.Tensor 'I13_5:0' shape=(?, 1) dtype=float32>)])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='C1', vocabulary_size=526, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C1', group_name='default_group'),\n",
       " SparseFeat(name='C2', vocabulary_size=516, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C2', group_name='default_group'),\n",
       " SparseFeat(name='C3', vocabulary_size=46456, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C3', group_name='default_group'),\n",
       " SparseFeat(name='C4', vocabulary_size=25777, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C4', group_name='default_group'),\n",
       " SparseFeat(name='C5', vocabulary_size=145, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C5', group_name='default_group'),\n",
       " SparseFeat(name='C6', vocabulary_size=12, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C6', group_name='default_group'),\n",
       " SparseFeat(name='C7', vocabulary_size=8057, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C7', group_name='default_group'),\n",
       " SparseFeat(name='C8', vocabulary_size=244, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C8', group_name='default_group'),\n",
       " SparseFeat(name='C9', vocabulary_size=3, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C9', group_name='default_group'),\n",
       " SparseFeat(name='C10', vocabulary_size=11906, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C10', group_name='default_group'),\n",
       " SparseFeat(name='C11', vocabulary_size=3913, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C11', group_name='default_group'),\n",
       " SparseFeat(name='C12', vocabulary_size=42651, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C12', group_name='default_group'),\n",
       " SparseFeat(name='C13', vocabulary_size=2882, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C13', group_name='default_group'),\n",
       " SparseFeat(name='C14', vocabulary_size=25, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C14', group_name='default_group'),\n",
       " SparseFeat(name='C15', vocabulary_size=5302, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C15', group_name='default_group'),\n",
       " SparseFeat(name='C16', vocabulary_size=35697, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C16', group_name='default_group'),\n",
       " SparseFeat(name='C17', vocabulary_size=10, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C17', group_name='default_group'),\n",
       " SparseFeat(name='C18', vocabulary_size=2606, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C18', group_name='default_group'),\n",
       " SparseFeat(name='C19', vocabulary_size=1273, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C19', group_name='default_group'),\n",
       " SparseFeat(name='C20', vocabulary_size=4, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C20', group_name='default_group'),\n",
       " SparseFeat(name='C21', vocabulary_size=39703, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C21', group_name='default_group'),\n",
       " SparseFeat(name='C22', vocabulary_size=12, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C22', group_name='default_group'),\n",
       " SparseFeat(name='C23', vocabulary_size=14, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C23', group_name='default_group'),\n",
       " SparseFeat(name='C24', vocabulary_size=12217, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C24', group_name='default_group'),\n",
       " SparseFeat(name='C25', vocabulary_size=51, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C25', group_name='default_group'),\n",
       " SparseFeat(name='C26', vocabulary_size=9375, embedding_dim=1, use_hash=False, dtype='int32', embedding_name='C26', group_name='default_group'),\n",
       " DenseFeat(name='I1', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I2', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I3', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I4', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I5', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I6', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I7', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I8', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I9', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I10', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I11', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I12', dimension=1, dtype='float32'),\n",
       " DenseFeat(name='I13', dimension=1, dtype='float32')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gason\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\initializers.py:143: calling RandomNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\gason\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\gason\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:253: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 64000 samples, validate on 16000 samples\n",
      "WARNING:tensorflow:From C:\\Users\\gason\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/10\n",
      "64000/64000 - 24s - loss: 0.5181 - binary_crossentropy: 0.5175 - val_loss: 0.5039 - val_binary_crossentropy: 0.5025\n",
      "Epoch 2/10\n",
      "64000/64000 - 20s - loss: 0.3732 - binary_crossentropy: 0.3703 - val_loss: 0.5685 - val_binary_crossentropy: 0.5639\n",
      "Epoch 3/10\n",
      "64000/64000 - 23s - loss: 0.2429 - binary_crossentropy: 0.2378 - val_loss: 0.6332 - val_binary_crossentropy: 0.6274\n",
      "Epoch 4/10\n",
      "64000/64000 - 24s - loss: 0.1913 - binary_crossentropy: 0.1853 - val_loss: 0.7347 - val_binary_crossentropy: 0.7285\n",
      "Epoch 5/10\n",
      "64000/64000 - 25s - loss: 0.1607 - binary_crossentropy: 0.1545 - val_loss: 0.8583 - val_binary_crossentropy: 0.8520\n",
      "Epoch 6/10\n",
      "64000/64000 - 27s - loss: 0.1375 - binary_crossentropy: 0.1312 - val_loss: 1.0590 - val_binary_crossentropy: 1.0527\n",
      "Epoch 7/10\n",
      "64000/64000 - 23s - loss: 0.1180 - binary_crossentropy: 0.1118 - val_loss: 1.2085 - val_binary_crossentropy: 1.2023\n",
      "Epoch 8/10\n",
      "64000/64000 - 22s - loss: 0.1015 - binary_crossentropy: 0.0954 - val_loss: 1.4172 - val_binary_crossentropy: 1.4112\n",
      "Epoch 9/10\n",
      "64000/64000 - 23s - loss: 0.0878 - binary_crossentropy: 0.0818 - val_loss: 1.5367 - val_binary_crossentropy: 1.5307\n",
      "Epoch 10/10\n",
      "64000/64000 - 22s - loss: 0.0763 - binary_crossentropy: 0.0704 - val_loss: 1.7434 - val_binary_crossentropy: 1.7376\n",
      "test LogLoss nan\n",
      "test AUC 0.6484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:2174: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.models import DeepFM\n",
    "from deepctr.inputs import  SparseFeat, DenseFeat, get_feature_names\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/train.csv')\n",
    "\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']\n",
    "\n",
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, vocabulary_size=data[feat].nunique(),embedding_dim=4)\n",
    "                       for i,feat in enumerate(sparse_features)] + [DenseFeat(feat, 1,)\n",
    "                      for feat in dense_features]\n",
    "\n",
    "dnn_feature_columns = fixlen_feature_columns\n",
    "linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "# 3.generate input data for model\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train_model_input = {name:train[name] for name in feature_names}\n",
    "test_model_input = {name:test[name] for name in feature_names}\n",
    "\n",
    "# 4.Define Model,train,predict and evaluate\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary')\n",
    "model.compile(\"adam\", \"binary_crossentropy\",\n",
    "              metrics=['binary_crossentropy'], )\n",
    "\n",
    "history = model.fit(train_model_input, train[target].values,\n",
    "                    batch_size=256, epochs=10, verbose=2, validation_split=0.2, )\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = build_input_features(\n",
    "    linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "inputs_list = list(features.values())\n",
    "\n",
    "group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,\n",
    "                                                                    init_std, seed, support_group=True)\n",
    "\n",
    "linear_logit = get_linear_logit(features, linear_feature_columns, init_std=init_std, seed=seed, prefix='linear',\n",
    "                                l2_reg=l2_reg_linear)\n",
    "fm_logit = add_func([FM()(concat_func(v, axis=1))\n",
    "                     for k, v in group_embedding_dict.items() if k in fm_group])\n",
    "\n",
    "dnn_input = combined_dnn_input(list(chain.from_iterable(\n",
    "    group_embedding_dict.values())), dense_value_list)\n",
    "dnn_output = DNN(dnn_hidden_units, dnn_activation, l2_reg_dnn, dnn_dropout,\n",
    "                 dnn_use_bn, seed)(dnn_input)\n",
    "dnn_logit = tf.keras.layers.Dense(\n",
    "    1, use_bias=False, activation=None)(dnn_output)\n",
    "\n",
    "final_logit = add_func([linear_logit, fm_logit, dnn_logit])\n",
    "\n",
    "output = PredictionLayer(task)(final_logit)\n",
    "model = tf.keras.models.Model(inputs=inputs_list, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<tf.Tensor 'sparse_emb_C1_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C2_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C3_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C4_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C5_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C6_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C7_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C8_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C9_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C10_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C11_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C12_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C13_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C14_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C15_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C16_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C17_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C18_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C19_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C20_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C21_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C22_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C23_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C24_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C25_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>,\n",
       "  <tf.Tensor 'sparse_emb_C26_1/embedding_lookup/Identity_1:0' shape=(?, 1, 1) dtype=float32>]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v for k,v in group_embedding_dict.items() if k in fm_group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(Layer):\n",
    "    \"\"\"Factorization Machine models pairwise (order-2) feature interactions\n",
    "     without linear term and bias.\n",
    "\n",
    "      Input shape\n",
    "        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
    "\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, 1)``.\n",
    "\n",
    "      References\n",
    "        - [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        super(FM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError(\"Unexpected inputs dimensions % d,\\\n",
    "                             expect to be 3 dimensions\" % (len(input_shape)))\n",
    "\n",
    "        super(FM, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "\n",
    "        if K.ndim(inputs) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\"\n",
    "                % (K.ndim(inputs)))\n",
    "\n",
    "        concated_embeds_value = inputs\n",
    "\n",
    "        square_of_sum = tf.square(reduce_sum(\n",
    "            concated_embeds_value, axis=1, keep_dims=True))\n",
    "        sum_of_square = reduce_sum(\n",
    "            concated_embeds_value * concated_embeds_value, axis=1, keep_dims=True)\n",
    "        cross_term = square_of_sum - sum_of_square\n",
    "        cross_term = 0.5 * reduce_sum(cross_term, axis=2, keep_dims=False)\n",
    "\n",
    "        return cross_term\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
