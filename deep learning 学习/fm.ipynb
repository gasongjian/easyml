{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# FM 算法介绍\n",
    "\n",
    "## 一、算法原理\n",
    "\n",
    "最早的广告点击率预估应用算法LR本质上其实是一个线性回归，数学表达为：\n",
    "\n",
    "$$\n",
    "y:= w_0+\\sum_{i=1}^{n} w_ix_i\n",
    "$$\n",
    "\n",
    "为了让模型能够表征相互关联特征的融合表达，通常的做法是用多项式来表示，因此对于有限的n维特征，特征的两两组合一共有(n(n-1))/2个新特征，FM的模型参数总计为(n(n+1))/2+1，可训练参数为n(k+1)+1，数学表达式为：\n",
    "\n",
    "$$\n",
    "y:=w_0+\\sum_{i=1}^{n} w_i x_i+\\sum_{i=1}^{n} \\sum_{j=i+1}^{n} w_{ij}x_ix_j\n",
    "$$\n",
    "\n",
    "但是这样模型参数以幂级增长，特征维度增加不可避免会带来特征的大规模稀疏性。注意到这里的$w$实际上是一个对称矩阵，我们可以用低矩阵逼近：\n",
    "\n",
    "$$\n",
    "\\big(w_{ij}\\big) \\approx V^{T}\\cdot V = \\big(<v_{i},v_{j}>\\big)\n",
    "$$\n",
    "\n",
    "其中 $v_i$ 是一个k维向量，相当于我们给第i个特征引入了一个低维隐向量。于是FM 可以写成\n",
    "\n",
    "$$\n",
    "y:=w_0+\\sum_{i=1}^{n} w_i x_i+\\sum_{i=1}^{n} \\sum_{j=i+1}^{n} <v_i,v_j> x_ix_j\n",
    "$$\n",
    "\n",
    "\n",
    "**FM 适用预测任务**： \n",
    "\n",
    "- Regression：FM 本质上是广义线模，能够通过最小化MSE 损失来实现回归预测；\n",
    "- Binary classification：FM 模型输出结果施加一个 sigmoid 函数通过最小化 binary crossentropy损失来实现二分类预测；\n",
    "- Ranking：通过对向量 X预测的分数 Y，可以对成对向量(X1,X2)进行排序。 \n",
    "\n",
    " \n",
    "\n",
    "**FM 算法优点**：\n",
    "\n",
    "- 对稀疏数据能够进行有效的参数估计；\n",
    "- FM 模型的具有线性的时间复杂度，计算速度快；\n",
    "- FM 模型能够拟合任意实数特征的二次项参数分布；\n",
    "\n",
    "## 二、keras 实现\n",
    "\n",
    "### 安装\n",
    "\n",
    "```shell\n",
    "pip install --user tensorflow==1.14\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FM(Layer):\n",
    "    \"\"\"Factorization Machine models pairwise (order-2) feature interactions\n",
    "     without linear term and bias.\n",
    "\n",
    "      Input shape\n",
    "        - 3D tensor with shape: ``(batch_size,field_size,embedding_size)``.\n",
    "\n",
    "      Output shape\n",
    "        - 2D tensor with shape: ``(batch_size, 1)``.\n",
    "\n",
    "      References\n",
    "        - [Factorization Machines](https://www.csie.ntu.edu.tw/~b97053/paper/Rendle2010FM.pdf)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        super(FM, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) != 3:\n",
    "            raise ValueError(\"Unexpected inputs dimensions % d,\\\n",
    "                             expect to be 3 dimensions\" % (len(input_shape)))\n",
    "\n",
    "        super(FM, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "\n",
    "        if K.ndim(inputs) != 3:\n",
    "            raise ValueError(\n",
    "                \"Unexpected inputs dimensions %d, expect to be 3 dimensions\"\n",
    "                % (K.ndim(inputs)))\n",
    "\n",
    "        concated_embeds_value = inputs\n",
    "\n",
    "        square_of_sum = tf.square(reduce_sum(\n",
    "            concated_embeds_value, axis=1, keep_dims=True))\n",
    "        sum_of_square = reduce_sum(\n",
    "            concated_embeds_value * concated_embeds_value, axis=1, keep_dims=True)\n",
    "        cross_term = square_of_sum - sum_of_square\n",
    "        cross_term = 0.5 * reduce_sum(cross_term, axis=2, keep_dims=False)\n",
    "\n",
    "        return cross_term\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a075f5df36dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gason\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\gason\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/3\n",
      "455/455 [==============================] - 0s 550us/sample - loss: 141.5931 - binary_accuracy: 0.6945 - val_loss: 43.1711 - val_binary_accuracy: 0.7544\n",
      "Epoch 2/3\n",
      "455/455 [==============================] - 0s 120us/sample - loss: 19.1017 - binary_accuracy: 0.8791 - val_loss: 21.3701 - val_binary_accuracy: 0.8772\n",
      "Epoch 3/3\n",
      "455/455 [==============================] - 0s 153us/sample - loss: 15.6643 - binary_accuracy: 0.8901 - val_loss: 18.5685 - val_binary_accuracy: 0.8596\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "K = tf.keras.backend\n",
    "\n",
    "\n",
    "\n",
    "def lr_model():\n",
    "    inputs = tf.keras.Input((30,))\n",
    "    pred = tf.keras.layers.Dense(units=1, \n",
    "                                 bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l1(0.02),\n",
    "                                 activation=tf.nn.sigmoid)(inputs)\n",
    "    lr = tf.keras.Model(inputs, pred)\n",
    "    lr.compile(loss='binary_crossentropy',\n",
    "               optimizer=tf.train.AdamOptimizer(0.001),\n",
    "               metrics=['binary_accuracy'])\n",
    "    return lr\n",
    "\n",
    "\n",
    "class MyLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim=30, **kwargs):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(self.input_dim, self.output_dim),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        a = K.pow(K.dot(x,self.kernel), 2)\n",
    "        b = K.dot(K.pow(x, 2), K.pow(self.kernel, 2))\n",
    "        return K.mean(a-b, 1, keepdims=True)*0.5\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "def FM(feature_dim):\n",
    "    inputs = tf.keras.Input((feature_dim,))\n",
    "    liner = tf.keras.layers.Dense(units=1, \n",
    "                                  bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l1(0.02),\n",
    "                                  )(inputs)\n",
    "    cross = MyLayer(feature_dim)(inputs)\n",
    "    add = tf.keras.layers.Add()([liner, cross])\n",
    "    predictions = tf.keras.layers.Activation('sigmoid')(add)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.train.AdamOptimizer(0.001),\n",
    "                  metrics=['binary_accuracy'])\n",
    "    return model\n",
    "\n",
    "def train():\n",
    "    fm = FM(30)\n",
    "    data = load_breast_cancer()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2,\n",
    "                                                        random_state=27, stratify=data.target)\n",
    "    fm.fit(X_train, y_train, epochs=3, batch_size=16, validation_data=(X_test, y_test))\n",
    "    return fm\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fm = train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
